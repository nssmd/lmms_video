# å¿«æ…¢å¸§è‡ªå›å½’è®­ç»ƒæŒ‡å—

LLaVA-NeXT é£æ ¼çš„å¿«æ…¢å¸§è‡ªå›å½’è§†é¢‘é‡å»ºï¼Œé›†æˆåˆ° lmms-engine æ¡†æ¶ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. å¿«æ…¢å¸§æœºåˆ¶

- **æ…¢å¸§ (Slow Frames)**: ä½¿ç”¨ `stride=4` çš„æ± åŒ–ï¼Œä¿ç•™æ›´å¤š patchesï¼Œæ•æ‰ç»†èŠ‚
- **å¿«å¸§ (Fast Frames)**: ä½¿ç”¨ `stride=8` çš„æ± åŒ–ï¼Œpatches æ›´å°‘ï¼Œæ›´å¤§æ„Ÿå—é‡
- **ç©¿æ’æ’åˆ—**: å¿«æ…¢å¸§äº¤æ›¿å‡ºç°ï¼Œä¾‹å¦‚ `S F S F S F...`

### 2. è‡ªå›å½’ç”Ÿæˆ

- å¸§çº§åˆ«å› æœ mask: æ¯ä¸€å¸§åªèƒ½çœ‹åˆ°ä¹‹å‰çš„å¸§
- è€ƒè™‘ä¸åŒå¸§çš„ patches æ•°é‡å·®å¼‚
- æ”¯æŒå¹¶è¡Œå¤„ç†å¤šä¸ªæ—¶é—´æ­¥

### 3. é›†æˆåˆ° lmms-engine

- æ— éœ€é‡å†™è®­ç»ƒå¾ªç¯
- ç›´æ¥ä½¿ç”¨ YAML é…ç½®
- æ”¯æŒå¤š GPU è®­ç»ƒ
- è‡ªåŠ¨æ—¥å¿—å’Œ checkpoint

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
cd /home/aiscuser/lmms-engine-mini/lmms_video

# å®‰è£…ä¾èµ–
pip install -e .

# éªŒè¯å®‰è£…
python -c "from lmms_engine.models.fast_slow_autoregressive import FastSlowAutoregressiveModule; print('âœ… å¿«æ…¢å¸§æ¨¡å—å·²å®‰è£…')"
```

### 2. å‡†å¤‡æ•°æ®

**é€‰é¡¹ A: ä» HuggingFace åŠ è½½ï¼ˆæ¨èï¼‰**
```bash
# æ•°æ®ä¼šè‡ªåŠ¨ä¸‹è½½
DATASET_PATH="lmms-lab/LLaVA-Video-178K"
```

**é€‰é¡¹ B: ä½¿ç”¨æœ¬åœ°æ•°æ®**
```bash
# ä¸‹è½½åˆ°æœ¬åœ°
git clone https://huggingface.co/datasets/lmms-lab/LLaVA-Video-178K /path/to/data

# æˆ–è€…ç›´æ¥ä½¿ç”¨ parquet æ–‡ä»¶ç›®å½•
DATASET_PATH="/path/to/LLaVA-Video-178K"
```

### 3. ä¿®æ”¹é…ç½®

ç¼–è¾‘ `configs/fast_slow_autoregressive.yaml`:

```yaml
# æ•°æ®è·¯å¾„
data_path: "lmms-lab/LLaVA-Video-178K"  # æˆ–æœ¬åœ°è·¯å¾„

# å¿«æ…¢å¸§é…ç½®
autoregressive_config:
  mm_spatial_pool_stride: 4              # æ…¢å¸§æ± åŒ–æ­¥é•¿
  frame_sampling_strategy: "interleave"   # å¿«æ…¢å¸§é‡‡æ ·ç­–ç•¥
  slow_frame_ratio: 0.5                   # æ…¢å¸§å æ¯”
  loss_weight: 0.15                       # æŸå¤±æƒé‡
```

### 4. å¯åŠ¨è®­ç»ƒ

```bash
cd /home/aiscuser/lmms-engine-mini/lmms_video

# ä½¿ç”¨æä¾›çš„è„šæœ¬
bash scripts/train_fast_slow.sh
```

æˆ–è€…æ‰‹åŠ¨å¯åŠ¨ï¼š

```bash
# å•å¡
python -m lmms_engine.train.runner \
    --config configs/fast_slow_autoregressive.yaml

# å¤šå¡ (8å¡)
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7

torchrun --nproc_per_node=8 \
    -m lmms_engine.train.runner \
    --config configs/fast_slow_autoregressive.yaml
```

## ğŸ“ é…ç½®è¯´æ˜

### å¿«æ…¢å¸§æ ¸å¿ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `mm_spatial_pool_stride` | 4 | æ…¢å¸§æ± åŒ–æ­¥é•¿ |
| `frame_sampling_strategy` | `interleave` | å¸§é‡‡æ ·ç­–ç•¥ |
| `slow_frame_ratio` | 0.5 | æ…¢å¸§å æ¯” |
| `loss_weight` | 0.15 | è‡ªå›å½’æŸå¤±æƒé‡ |

### å¸§é‡‡æ ·ç­–ç•¥

1. **`interleave`** (äº¤æ›¿): `S F S F S F S F ...`
   - å¿«æ…¢å¸§å‡åŒ€åˆ†å¸ƒ
   - é€‚åˆéœ€è¦å¹³è¡¡ç»†èŠ‚å’Œå…¨å±€çš„åœºæ™¯

2. **`first_slow`** (å‰æ…¢åå¿«): `S S S S ... F F F F`
   - å‰é¢ç”¨æ…¢å¸§æ•æ‰åˆå§‹ç»†èŠ‚
   - åé¢ç”¨å¿«å¸§å¿«é€Ÿè¿‡æ¸¡

3. **`uniform`** (å‡åŒ€åˆ†å¸ƒ): æ ¹æ® `slow_frame_ratio` å‡åŒ€åˆ†å¸ƒæ…¢å¸§
   - çµæ´»æ§åˆ¶æ…¢å¸§ä½ç½®
   - é€‚åˆå®éªŒä¸åŒé…ç½®

### è®­ç»ƒå‚æ•°å»ºè®®

```yaml
# å¯¹äº Qwen2-VL-7B
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 2e-5
max_frames_num: 16

# å¯¹äºæ›´å¤§æ¨¡å‹ï¼ˆ72Bï¼‰
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
learning_rate: 1e-5
max_frames_num: 8  # å‡å°‘å¸§æ•°ä»¥èŠ‚çœå†…å­˜
```

## ğŸ” éªŒè¯è®­ç»ƒ

### 1. æŸ¥çœ‹æ—¥å¿—

```bash
# è®­ç»ƒæ—¥å¿—
tail -f output/fast_slow_autoregressive_*/train.log

# æŸ¥æ‰¾è‡ªå›å½’æŸå¤±
grep "autoregressive_loss" output/fast_slow_autoregressive_*/train.log
```

### 2. TensorBoard

```bash
tensorboard --logdir output/fast_slow_autoregressive_*/logs
```

### 3. æ£€æŸ¥ Checkpoint

```bash
ls -lh output/fast_slow_autoregressive_*/checkpoint-*
```

## ğŸ› å¸¸è§é—®é¢˜

### 1. å†…å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å‡å°‘batch size
per_device_train_batch_size: 1

# å‡å°‘å¸§æ•°
max_frames_num: 8

# å¢åŠ å¿«å¸§æ¯”ä¾‹ï¼ˆå¿«å¸§patcheså°‘ï¼Œå†…å­˜å ç”¨å°ï¼‰
slow_frame_ratio: 0.3

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
gradient_checkpointing: true
```

### 2. æ‰¾ä¸åˆ°æ¨¡å—

```bash
# ç¡®ä¿åœ¨æ­£ç¡®ç›®å½•
cd /home/aiscuser/lmms-engine-mini/lmms_video

# é‡æ–°å®‰è£…
pip install -e .

# éªŒè¯
python -c "from lmms_engine.models.fast_slow_autoregressive import FastSlowAutoregressiveModule"
```

### 3. æ•°æ®åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ•°æ®é›†è·¯å¾„
ls -la /path/to/LLaVA-Video-178K

# ä½¿ç”¨ HuggingFaceï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰
data_path: "lmms-lab/LLaVA-Video-178K"

# æµ‹è¯•æ•°æ®åŠ è½½
python -c "from datasets import load_dataset; ds = load_dataset('lmms-lab/LLaVA-Video-178K', split='train', streaming=True); print(next(iter(ds)))"
```

### 4. æŸå¤±ä¸ä¸‹é™

**æ£€æŸ¥é…ç½®**:
```yaml
# ç¡®ä¿å¯ç”¨è¾“å‡ºhidden states
output_hidden_states: true

# ç¡®ä¿æŸå¤±æƒé‡åˆé€‚
loss_weight: 0.15  # ä¸è¦å¤ªå°ï¼Œä¹Ÿä¸è¦å¤ªå¤§

# æ£€æŸ¥å­¦ä¹ ç‡
learning_rate: 2e-5  # å¯ä»¥å°è¯• 1e-5 åˆ° 5e-5
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–

```yaml
dataloader_num_workers: 4
dataloader_pin_memory: true
dataloader_persistent_workers: true
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ

```yaml
bf16: true  # æ¨è
tf32: true
fp16: false # ä¸æ¨èï¼Œç²¾åº¦æŸå¤±è¾ƒå¤§
```

### 3. æ¢¯åº¦ç´¯ç§¯

```yaml
# æœ‰æ•ˆ batch size = per_device_batch_size * num_gpus * gradient_accumulation_steps
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
# 8å¡: æœ‰æ•ˆbatch size = 2 * 8 * 8 = 128
```

## ğŸ“ˆ å®éªŒå»ºè®®

### 1. æ¶ˆèå®éªŒ

æµ‹è¯•ä¸åŒé…ç½®çš„å½±å“ï¼š

```yaml
# å®éªŒ1: åªç”¨æ…¢å¸§ï¼ˆbaselineï¼‰
slow_frame_ratio: 1.0

# å®éªŒ2: åªç”¨å¿«å¸§
slow_frame_ratio: 0.0

# å®éªŒ3: 50-50 æ··åˆï¼ˆæ¨èï¼‰
slow_frame_ratio: 0.5

# å®éªŒ4: 70% æ…¢å¸§
slow_frame_ratio: 0.7
```

### 2. é‡‡æ ·ç­–ç•¥å¯¹æ¯”

```yaml
# æµ‹è¯•ä¸‰ç§ç­–ç•¥
frame_sampling_strategy: "interleave"  # vs "first_slow" vs "uniform"
```

### 3. æŸå¤±æƒé‡è°ƒä¼˜

```yaml
# ä»å°åˆ°å¤§æµ‹è¯•
loss_weight: 0.05  # è½»é‡çº§
loss_weight: 0.10  # å¹³è¡¡
loss_weight: 0.15  # æ¨è
loss_weight: 0.20  # æ¿€è¿›
```

## ğŸ”— ç›¸å…³æ–‡ä»¶

- **æ ¸å¿ƒæ¨¡å—**: `src/lmms_engine/models/fast_slow_autoregressive.py`
- **Trainer**: `src/lmms_engine/train/autoregressive_trainer.py`
- **é…ç½®æ–‡ä»¶**: `configs/fast_slow_autoregressive.yaml`
- **å¯åŠ¨è„šæœ¬**: `scripts/train_fast_slow.sh`
- **ç¤ºä¾‹**: `examples/train_with_autoregressive.py`

## ğŸ“š å‚è€ƒ

- LLaVA-NeXT: https://github.com/LLaVA-VL/LLaVA-NeXT
- LLaVA-Video-178K: https://huggingface.co/datasets/lmms-lab/LLaVA-Video-178K
- lmms-engine: https://github.com/lmms-lab/lmms-engine

---

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–æäº¤ Issueã€‚