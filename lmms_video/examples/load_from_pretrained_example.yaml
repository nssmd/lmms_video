- type: trainer
  config:
    trainer_type: hf_trainer

    # Dataset configuration - now includes the actual dataset definitions
    dataset_config:
      dataset_type: vision
      dataset_format: yaml # Uses 'yaml' format for both external files and inline definitions

      # Inline dataset definitions (no dataset_path needed)
      datasets:
        - path: data/open_thoughts_debug
          data_folder: ""
          data_type: arrow

      # Processor configuration
      processor_config:
        processor_name: "Qwen/Qwen2.5-VL-7B-Instruct"
        processor_type: "qwen2_5_vl"

      # Packing configuration
      packing: true
      packing_strategy: first_fit
      packing_length: 16384

    # Model configuration
    model_config:
      load_from_pretrained_path: "Qwen/Qwen2.5-VL-7B-Instruct"
      attn_implementation: "flash_attention_2"

    # Training arguments, mostly compatible with HuggingFace Trainer
    per_device_train_batch_size: 1
    learning_rate: 1.0e-06 # we should use 1.0 to makes YAML recognize it as a float
    weight_decay: 0.0
    gradient_accumulation_steps: 1
    gradient_checkpointing: true
    num_train_epochs: 1
    save_steps: 100
    save_total_limit: 1
    report_to: "wandb"
    output_dir: "./output/debug"
    warmup_ratio: 0.0
    run_name: "qwen2_5_vl_config"
    eval_strategy: "no"
    logging_steps: 1
    group_by_length: true
    dataloader_num_workers: 8
    bf16: true
    lr_scheduler_type: "cosine"
    freeze_modules: ["visual"]
    use_liger_kernel: true
    use_rmpad: true
    fsdp2: true
    fsdp_config:
      transformer_layer_cls_to_wrap: ["Qwen2_5_VLDecoderLayer"]
      reshard_after_forward: false
