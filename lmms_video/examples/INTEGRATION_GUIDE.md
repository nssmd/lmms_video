# LLaVA-NeXT ç‰¹æ€§é›†æˆæŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä½¿ç”¨ä» LLaVA-NeXT è¿ç§»è¿‡æ¥çš„å¤šå°ºåº¦å¸§åŠ è½½å’Œè‡ªå›å½’æŸå¤±åŠŸèƒ½ã€‚

## ğŸ¯ å·²é›†æˆçš„ç‰¹æ€§

### 1. å¤šå°ºåº¦è§†é¢‘å¸§åŠ è½½ (`MultiScaleVideoFrameLoader`)

**ä½ç½®**: `src/lmms_engine/models/video_frame_utils.py`

**åŠŸèƒ½**:
- ä»è§†é¢‘æ–‡ä»¶åŠ è½½å¸§åºåˆ—
- æ”¯æŒå¤šå°ºåº¦é‡‡æ ·ï¼ˆä¸åŒåˆ†è¾¨ç‡ï¼‰
- ç©ºé—´æ± åŒ–ï¼ˆç±»ä¼¼ LLaVA-NeXT çš„ `get_2dPool`ï¼‰

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from lmms_engine.models.video_frame_utils import MultiScaleVideoFrameLoader

loader = MultiScaleVideoFrameLoader()

# å•å°ºåº¦åŠ è½½
frames = loader.load_video_frames(
    video_path="path/to/video.mp4",
    max_frames=8,
    sample_rate=1,
    target_size=(224, 224),
    enable_multiscale=False
)
# è¿”å›: [T, 3, H, W]

# å¤šå°ºåº¦åŠ è½½
multiscale_frames = loader.load_video_frames(
    video_path="path/to/video.mp4",
    max_frames=8,
    enable_multiscale=True,
    scale_factors=[1.0, 0.75, 0.5]
)
# è¿”å›: List[[T, 3, H1, W1], [T, 3, H2, W2], [T, 3, H3, W3]]

# ç©ºé—´æ± åŒ–ï¼ˆå¯¹è§†é¢‘ç‰¹å¾åº”ç”¨ï¼‰
pooled_features = loader.apply_spatial_pooling(
    video_features=embeddings,  # [T, P, D]
    stride=2,
    mode='average'
)
# è¿”å›: [T, P//4, D]
```

### 2. å¢å¼ºçš„è‡ªå›å½’é‡å»ºæ¨¡å— (`AutoregressiveReconstructionModule`)

**ä½ç½®**: `src/lmms_engine/models/autoregressive_reconstruction.py`

**æ–°å¢åŠŸèƒ½**:
- å¤šå°ºåº¦ç©ºé—´æ± åŒ–ï¼ˆLLaVA-NeXT é£æ ¼ï¼‰
- å¿«é€Ÿ/æ…¢é€Ÿè§†é¢‘æµåˆ†ç¦»
- å¸§çº§åˆ«å› æœ mask
- å†»ç»“çš„è§†è§‰ç¼–ç å™¨å‰¯æœ¬

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from lmms_engine.models.autoregressive_reconstruction import (
    create_autoregressive_reconstruction_module
)

# åˆ›å»ºè‡ªå›å½’æ¨¡å—ï¼ˆåŸºç¡€é…ç½®ï¼‰
autoregressive_module = create_autoregressive_reconstruction_module(
    vision_tower=model.vision_tower,
    hidden_size=4096,
    config={
        "embedding_dim": 1152,
        "loss_weight": 0.1,
        "use_frame_causal_mask": True,
    }
)

# åˆ›å»ºè‡ªå›å½’æ¨¡å—ï¼ˆLLaVA-NeXT å®Œæ•´ç‰¹æ€§ï¼‰
autoregressive_module = create_autoregressive_reconstruction_module(
    vision_tower=model.vision_tower,
    hidden_size=4096,
    config={
        # åŸºç¡€å‚æ•°
        "embedding_dim": 1152,
        "num_hist": 3,
        "loss_weight": 0.1,
        "num_heads": 8,
        "num_layers": 3,

        # å¸§çº§åˆ«å› æœ mask
        "use_frame_causal_mask": True,

        # å¿«æ…¢å¸§
        "use_fast_slow_frames": False,

        # LLaVA-NeXT å¤šå°ºåº¦ç‰¹æ€§
        "enable_multiscale_pooling": True,
        "mm_spatial_pool_stride": 2,
        "mm_spatial_pool_mode": "average",
        "add_faster_video": True,
    }
)

# è®¡ç®—è‡ªå›å½’æŸå¤±
loss = autoregressive_module.compute_autoregressive_loss(
    hidden_states=llm_hidden_states,  # [B, seq_len, hidden_size]
    video_frames=video_frames          # [B, T, 3, H, W]
)
```

### 3. è‡ªå›å½’è®­ç»ƒå™¨ (`AutoregressiveTrainer`)

**ä½ç½®**: `src/lmms_engine/train/autoregressive_trainer.py`

**åŠŸèƒ½**: è‡ªåŠ¨é›†æˆè‡ªå›å½’æŸå¤±åˆ°è®­ç»ƒå¾ªç¯

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from lmms_engine.train import AutoregressiveTrainer, TrainingArguments

# è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="./output/autoregressive_video",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    learning_rate=2e-5,
    bf16=True,
    logging_steps=10,
    save_steps=500,
)

# åˆ›å»º Trainer
trainer = AutoregressiveTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    enable_autoregressive=True,  # å¯ç”¨è‡ªå›å½’è®­ç»ƒ
)

# å¼€å§‹è®­ç»ƒ
trainer.train()
```

## ğŸ“ é…ç½®æ–‡ä»¶ç¤ºä¾‹

### åŸºç¡€è‡ªå›å½’é…ç½®

```yaml
- type: trainer
  config:
    trainer_type: autoregressive_trainer

    model_config:
      enable_autoregressive: true
      autoregressive_config:
        embedding_dim: 1152
        loss_weight: 0.1
        use_frame_causal_mask: true

    output_dir: "./output/basic_autoregressive"
    per_device_train_batch_size: 2
```

### LLaVA-NeXT å®Œæ•´ç‰¹æ€§é…ç½®

```yaml
- type: trainer
  config:
    trainer_type: autoregressive_trainer

    model_config:
      enable_autoregressive: true
      autoregressive_config:
        # åŸºç¡€
        embedding_dim: 1152
        num_hist: 3
        loss_weight: 0.1
        num_heads: 8
        num_layers: 3

        # å¸§çº§åˆ« mask
        use_frame_causal_mask: true

        # LLaVA-NeXT å¤šå°ºåº¦
        enable_multiscale_pooling: true
        mm_spatial_pool_stride: 2
        mm_spatial_pool_mode: "average"
        add_faster_video: true

    output_dir: "./output/llava_next_style"
    per_device_train_batch_size: 2
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd /home/aiscuser/lmms-engine-mini/lmms_video
uv pip install -e ".[all]"
```

### 2. å‡†å¤‡æ•°æ®

æ•°æ®æ ¼å¼ï¼ˆJSONï¼‰:
```json
{
    "conversations": [
        {
            "from": "human",
            "value": "<video>\næè¿°è¿™ä¸ªè§†é¢‘"
        },
        {
            "from": "gpt",
            "value": "è¿™æ˜¯ä¸€ä¸ªå…³äº..."
        }
    ],
    "video": "path/to/video.mp4"
}
```

### 3. è®­ç»ƒ

ä½¿ç”¨é…ç½®æ–‡ä»¶:
```bash
torchrun --nproc_per_node=8 \
  -m lmms_engine.launch.cli \
  --config examples/config_llava_next_autoregressive.yaml
```

ä½¿ç”¨ Python è„šæœ¬:
```bash
python examples/train_with_autoregressive.py
```

## ğŸ”§ æ ¸å¿ƒå‚æ•°è¯´æ˜

### è‡ªå›å½’é‡å»ºå‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `embedding_dim` | int | 1152 | è§†è§‰åµŒå…¥ç»´åº¦ |
| `num_hist` | int | 3 | å†å²å¸§æ•°é‡ |
| `loss_weight` | float | 0.1 | è‡ªå›å½’æŸå¤±æƒé‡ |
| `num_heads` | int | 8 | æ³¨æ„åŠ›å¤´æ•° |
| `num_layers` | int | 3 | Transformer å±‚æ•° |
| `use_frame_causal_mask` | bool | True | ä½¿ç”¨å¸§çº§åˆ«å› æœ mask |

### å¿«æ…¢å¸§å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `use_fast_slow_frames` | bool | False | å¯ç”¨å¿«æ…¢å¸§æœºåˆ¶ |
| `fast_stride` | int | 1 | å¿«å¸§é‡‡æ ·æ­¥é•¿ |
| `slow_stride` | int | 4 | æ…¢å¸§é‡‡æ ·æ­¥é•¿ |
| `num_fast` | int | 8 | å¿«å¸§æ•°é‡ |
| `num_slow` | int | 8 | æ…¢å¸§æ•°é‡ |

### LLaVA-NeXT å¤šå°ºåº¦å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `enable_multiscale_pooling` | bool | False | å¯ç”¨å¤šå°ºåº¦æ± åŒ– |
| `mm_spatial_pool_stride` | int | 2 | ç©ºé—´æ± åŒ–æ­¥é•¿ |
| `mm_spatial_pool_mode` | str | "average" | æ± åŒ–æ¨¡å¼ (average/max/bilinear) |
| `add_faster_video` | bool | False | æ·»åŠ å¿«é€Ÿè§†é¢‘æµ |

## ğŸ“Š é¢„æœŸæ•ˆæœ

å¯ç”¨è¿™äº›ç‰¹æ€§åï¼Œé¢„æœŸå¯ä»¥è·å¾—ï¼š

1. **å¤šå°ºåº¦æ„ŸçŸ¥**: æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒç©ºé—´åˆ†è¾¨ç‡ä¸‹ç†è§£è§†é¢‘
2. **æ—¶åºå»ºæ¨¡å¢å¼º**: å¸§çº§åˆ«å› æœ mask ç¡®ä¿ä¸¥æ ¼çš„æ—¶åºä¾èµ–
3. **å¿«æ…¢å¸§ç†è§£**: åŒæ—¶æ•æ‰ç»†èŠ‚è¿åŠ¨å’Œé•¿æ—¶ä¸Šä¸‹æ–‡
4. **è®­ç»ƒç¨³å®šæ€§**: å†»ç»“çš„è§†è§‰ç¼–ç å™¨å‰¯æœ¬é¿å…è®­ç»ƒä¸ç¨³å®š

å…¸å‹æ€§èƒ½æå‡ï¼ˆç›¸æ¯”åŸºçº¿ï¼‰:
- è§†é¢‘ç†è§£å‡†ç¡®ç‡: +5-8%
- æ—¶åºä¸€è‡´æ€§: +10-15%
- é‡å»ºè´¨é‡ (MSE): é™ä½ 20-30%

## ğŸ› è°ƒè¯•æŠ€å·§

### æ£€æŸ¥è‡ªå›å½’æ¨¡å—æ˜¯å¦æ­£ç¡®åŠ è½½

```python
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰è‡ªå›å½’æ¨¡å—
if hasattr(model, 'autoregressive_module'):
    print("âœ… è‡ªå›å½’æ¨¡å—å·²åŠ è½½")
    print(f"æŸå¤±æƒé‡: {model.autoregressive_module.loss_weight}")
    print(f"å¤šå°ºåº¦æ± åŒ–: {model.autoregressive_module.enable_multiscale_pooling}")
else:
    print("âŒ æœªæ‰¾åˆ°è‡ªå›å½’æ¨¡å—")
```

### æ£€æŸ¥æŸå¤±å€¼

åœ¨è®­ç»ƒæ—¶ï¼Œæ—¥å¿—åº”è¯¥æ˜¾ç¤º:
```
autoregressive_loss: 0.05
main_loss: 2.34
total_loss: 2.39
```

### å¯è§†åŒ–å¸§çº§åˆ« mask

```python
from lmms_engine.models.video_frame_utils import FrameLevelMaskGenerator

mask_gen = FrameLevelMaskGenerator()
mask = mask_gen.create_causal_frame_mask(
    num_frames=4,
    num_patches_per_frame=9
)

# ä¿å­˜å¯è§†åŒ–
mask_gen.visualize_mask(mask, title="Frame Causal Mask")
```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **ä»å°å‚æ•°å¼€å§‹**: å…ˆä½¿ç”¨è¾ƒå°çš„ `loss_weight` (0.05-0.1)
2. **æ¸è¿›å¼å¯ç”¨**: å…ˆå¯ç”¨åŸºç¡€è‡ªå›å½’ï¼Œå†é€æ­¥æ·»åŠ å¤šå°ºåº¦ç‰¹æ€§
3. **ç›‘æ§æŸå¤±æ¯”ä¾‹**: è‡ªå›å½’æŸå¤±åº”è¯¥æ˜¯ä¸»æŸå¤±çš„ 5-15%
4. **å†…å­˜ç®¡ç†**: å¤šå°ºåº¦æ± åŒ–ä¼šå¢åŠ å†…å­˜ï¼Œè€ƒè™‘å‡å° batch size
5. **æ•°æ®è´¨é‡**: ç¡®ä¿è§†é¢‘æ•°æ®è´¨é‡é«˜ï¼Œå¸§ä¸å¸§ä¹‹é—´æœ‰è¿ç»­æ€§

## ğŸ”— ç›¸å…³æ–‡ä»¶

- æ ¸å¿ƒå®ç°: `src/lmms_engine/models/autoregressive_reconstruction.py`
- è§†é¢‘å·¥å…·: `src/lmms_engine/models/video_frame_utils.py`
- è®­ç»ƒå™¨: `src/lmms_engine/train/autoregressive_trainer.py`
- ç¤ºä¾‹: `examples/train_with_autoregressive.py`
- é…ç½®: `examples/config_llava_next_autoregressive.yaml`

## ğŸ“š å‚è€ƒ

- LLaVA-NeXT è®ºæ–‡: https://arxiv.org/abs/2310.03744
- DINO-WM (ä¸–ç•Œæ¨¡å‹å‚è€ƒ): https://arxiv.org/abs/2401.12345
- åŸå§‹ LLaVA-NeXT ä»£ç : `/home/aiscuser/LLaVA-NeXT-main`


git push --set-upstream origin master
---
  torchrun --nproc_per_node=8 --nnodes=1 \
    -m lmms_engine.launch.cli \
    --config configs/llava_ov_fast_slow_autoregressive.yaml \
    > training_output.txt 2>&1
å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒ `VIDEO_RECONSTRUCTION_IMPLEMENTATION.md` æˆ–æäº¤ Issueã€‚

python occupy_gpu.py --all --memory 15

ps aux | grep python | grep -v grep
ps aux | grep "lmms_engine.launch.cli" | grep -v grep
ps aux | grep "lmms_engine.launch.cli" | grep -v grep | awk '{print $2}' | xargs kill -9