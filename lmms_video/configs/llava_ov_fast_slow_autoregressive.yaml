# LLaVA-OneVision + å¿«æ…¢å¸§è‡ªå›å½’è®­ç»ƒé…ç½®
# ä½¿ç”¨æœ¬åœ° Parquet æ ¼å¼çš„ LLaVA-Video-178K æ•°æ®é›†
# é›†æˆå¿«æ…¢å¸§æœºåˆ¶å’Œè‡ªå›å½’è§†é¢‘é‡å»º

- type: trainer
  config:
    trainer_type: hf_trainer

    # ==================== æ•°æ®é›†é…ç½® ====================
    dataset_config:
      dataset_type: vision
      dataset_format: parquet  # ä½¿ç”¨ parquet æ ¼å¼

      # Parquet æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
      dataset_path: "/blob/LLaVA-Video-178K-parquet/*.parquet"
      
      # è§†é¢‘æ–‡ä»¶åŸºç¡€è·¯å¾„ï¼ˆparquet ä¸­çš„è§†é¢‘è·¯å¾„æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦æ‹¼æ¥è¿™ä¸ªåŸºç¡€è·¯å¾„ï¼‰
      data_folder: "/blob/LLaVA-Video-178K"

      # è§†é¢‘å¤„ç†å‚æ•°ï¼ˆä½¿ç”¨ DatasetConfig æ”¯æŒçš„å‚æ•°ï¼‰
      video_sampling_strategy: "frame_num"  # æˆ– "fps"
      frame_num: 16  # é‡‡æ ·å¸§æ•°
      fps: 1  # é‡‡æ ·å¸§ç‡ï¼ˆå½“ strategy ä¸º fps æ—¶ä½¿ç”¨ï¼‰
      video_backend: "decord"  # è§†é¢‘è§£ç åç«¯

      # Processor é…ç½®
      processor_config:
        processor_name: "llava-hf/llava-onevision-qwen2-7b-ov-hf"
        processor_type: "llava"  # ä½¿ç”¨ llava processor (LLaVA-OneVision å…¼å®¹)
        max_pixels: 1003520
        min_pixels: 4096

      # Packing é…ç½®
      packing: false

    # ==================== æ¨¡å‹é…ç½® ====================
    model_config:
      # LLaVA-OneVision åŸºç¡€æ¨¡å‹ (ä½¿ç”¨ 0.5B ç‰ˆæœ¬èŠ‚çœæ˜¾å­˜)
      load_from_pretrained_path: "llava-hf/llava-onevision-qwen2-0.5b-ov-hf"
      attn_implementation: "flash_attention_2"

      # æ‰€æœ‰é¢å¤–é…ç½®æ”¾åœ¨ overwrite_config ä¸­
      overwrite_config:
        # æ¨¡å‹é…ç½®å‚æ•°
        output_hidden_states: true

        # ğŸ”¥ å¯ç”¨è‡ªå›å½’é‡å»º
        enable_autoregressive: true

        # ğŸ”¥ğŸ”¥ å¿«æ…¢å¸§ + è‡ªå›å½’é…ç½® (LLaVA-NeXT é£æ ¼)
        autoregressive_config:
          # åŸºç¡€å‚æ•°
          embedding_dim: 1152
          # hidden_size ä¼šä»æ¨¡å‹ä¸»é…ç½®è‡ªåŠ¨è·å–ï¼Œä¸éœ€è¦åœ¨è¿™é‡ŒæŒ‡å®š
          loss_weight: 1.0  # 1:1 æƒé‡ï¼Œè‡ªå›å½’æŸå¤±ä¸è¯­è¨€æ¨¡å‹æŸå¤±åŒç­‰é‡è¦
          num_heads: 8
          num_layers: 3

          # LLaVA-NeXT ç©ºé—´æ± åŒ–å‚æ•°
          mm_spatial_pool_stride: 4
          mm_spatial_pool_mode: "average"
          add_faster_video: true  # å¯ç”¨å¿«å¸§å¤„ç†

          # å¿«æ…¢å¸§ç±»å‹åˆ†é…ç­–ç•¥
          frame_sampling_strategy: "interleave"  # interleave/periodic/uniform
          slow_frame_ratio: 0.25  # æ…¢å¸§æ¯”ä¾‹ (0.25 = æ¯4å¸§ä¸€ä¸ªæ…¢å¸§)

    # ==================== è®­ç»ƒå‚æ•° ====================
    output_dir: "./output/llava_ov_fast_slow_autoregressive"
    run_name: "llava_ov_fast_slow_ar"

    num_train_epochs: 3
    per_device_train_batch_size: 2
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 8

    learning_rate: 2.0e-5
    weight_decay: 0.01
    warmup_ratio: 0.03
    lr_scheduler_type: "cosine"
    optim: "adamw_torch"

    bf16: true
    tf32: true
    fp16: false

    max_grad_norm: 1.0
    gradient_checkpointing: true

    # ==================== DeepSpeed é…ç½® ====================
    deepspeed: "./configs/deepspeed_zero3.json"

    # ==================== æ—¥å¿—å’Œä¿å­˜ ====================
    logging_steps: 10
    save_strategy: "steps"
    save_steps: 500
    save_total_limit: 3
    eval_strategy: "no"

    logging_dir: "./logs"
    report_to: ["tensorboard"]
    logging_first_step: true

    # ==================== æ•°æ®åŠ è½½ ====================
    dataloader_num_workers: 4
    dataloader_pin_memory: true
    remove_unused_columns: false
    dataloader_persistent_workers: true

    # ==================== å…¶ä»– ====================
    seed: 42
    ddp_find_unused_parameters: true