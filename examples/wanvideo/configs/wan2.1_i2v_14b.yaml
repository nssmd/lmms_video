# WanVideo 2.1 I2V 14B Training Configuration
# Image-to-Video generation model

- task_type: trainer
  config:
    trainer_type: hf_trainer
    
    # Dataset configuration
    dataset_config:
      dataset_type: vision
      dataset_format: csv
      dataset_path: data/example_video_dataset/metadata.csv
      video_sampling_strategy: frame_num
      frame_num: 49
      video_backend: qwen_vl_utils
      
      # Processor configuration
      processor_config:
        processor_type: wanvideo
        do_resize: true
        size:
          height: 720
          width: 1280
        do_normalize: true
        image_mean: [0.5, 0.5, 0.5]
        image_std: [0.5, 0.5, 0.5]
    
    # Model configuration
    model_config:
      load_from_config:
        model_type: wanvideo
        model_variant: "Wan2.1-I2V-14B-720P"
        model_size: "14B"
        
        # DiT model parameters
        dit_hidden_size: 5120
        dit_num_layers: 48
        dit_num_heads: 40
        dit_patch_size: 2
        dit_patch_size_t: 1
        dit_in_channels: 16
        dit_mlp_ratio: 4.0
        dit_qk_norm: true
        dit_enable_flash_attn: true
        dit_rope_scaling_factor: 2.0
        dit_temporal_rope_scaling_factor: 2.0
        
        # VAE parameters
        vae_latent_channels: 16
        vae_scaling_factor: 0.33208
        
        # Text encoder
        text_encoder_model: "umt5-xxl-enc"
        text_encoder_hidden_size: 4096
        max_text_length: 256
        
        # Image encoder for I2V
        use_image_encoder: true
        image_encoder_model: "clip-vit-large-patch14"
        image_encoder_hidden_size: 1024
        
        # Training parameters
        num_train_timesteps: 1000
        scheduler_type: "flow_match"
        scheduler_shift: 5
        gradient_checkpointing: true
        
        # Generation defaults for 720p
        num_frames: 49
        height: 720
        width: 1280
        fps: 15
        guidance_scale: 7.0  # Higher guidance for I2V
        num_inference_steps: 25
      
      # Optional: Load pretrained weights
      # load_from_pretrained_path: "Wan-AI/Wan2.1-I2V-14B-720P"
      
      attn_implementation: flash_attention_2
    
    # Training arguments
    trainer_args:
      output_dir: "./output/wan2.1_i2v_14b_720p"
      num_train_epochs: 2
      per_device_train_batch_size: 1
      per_device_eval_batch_size: 1
      gradient_accumulation_steps: 32  # Higher due to larger resolution
      gradient_checkpointing: true
      
      learning_rate: 3.0e-6
      weight_decay: 0.01
      warmup_steps: 1000
      lr_scheduler_type: "cosine_with_restarts"
      
      logging_steps: 10
      save_steps: 200
      save_total_limit: 2
      
      dataloader_num_workers: 4
      
      fp16: false
      bf16: true
      tf32: true
      
      seed: 42
      
      # Optimization
      optim: "adamw_torch_fused"  # Fused optimizer for better performance
      adam_beta1: 0.9
      adam_beta2: 0.999
      adam_epsilon: 1.0e-8
      
      # Evaluation # currently do not support evaluation in wan video training
      # eval_strategy: "steps"
      # eval_steps: 200
      
      # Gradient clipping
      max_grad_norm: 0.5
      
      # FSDP configuration
      fsdp: "full_shard auto_wrap"
      fsdp_config:
        backward_prefetch: "backward_pre"
        forward_prefetch: true
        use_orig_params: false
        cpu_ram_efficient_loading: true
        sync_module_states: true
        limit_all_gathers: true
        activation_checkpointing: true
        sharding_strategy: "FULL_SHARD"
